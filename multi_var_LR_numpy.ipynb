{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"multiple-lr-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding x and y\n",
    "# y=np.array(df['loan'])\n",
    "# x1=np.array(df['age'])\n",
    "# x2=np.array(df['credit-rating'])\n",
    "# x3=np.array(df['children'])\n",
    "a=np.array(df)\n",
    "x1=a[:,0]\n",
    "x2=a[:,1]\n",
    "x3=a[:,2]\n",
    "x=np.concatenate((x1,x2,x3))\n",
    "y=a[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4014,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.reshape(1338,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test split\n",
    "x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.2, shuffle=False)\n",
    "# x_train2, x_test2, y_train, y_test = train_test_split( x2, y, test_size=0.2, shuffle=False)\n",
    "# x_train3, x_test3, y_train, y_test = train_test_split( x3, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform of x for multiplication\n",
    "# sc = StandardScaler()\n",
    "# x_train = sc.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h=t0+t1x1+t2x2+tnxn\n",
    "#J is same as single var\n",
    "#gradient is error X xj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "alpha=0.0001\n",
    "iterations=1000000\n",
    "t0=0.5\n",
    "t1=0.5\n",
    "t2=0.5\n",
    "t3=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction function\n",
    "def h(t0,t1,t2,t3):\n",
    "    return t0+(t1*x_train[:,0])+(t2*x_train[:,1])+(t3*x_train[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost function\n",
    "def get_cost(t0,t1,t2,t3):\n",
    "    preds=h(t0,t1,t2,t3)  #error\n",
    "    J=(preds-y_train)**2 #squaring\n",
    "    J=J.mean()\n",
    "    J=J/2 #gradient decsent looks good\n",
    "    #print(J)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing preds\n",
    "# def custom_plot(t0,t1,t2,t3):\n",
    "#     preds=h(t0,t1,t2,t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating gradients\n",
    "def get_gradients(t0,t1,t2,t3):\n",
    "    preds=h(t0,t1,t2,t3)\n",
    "    g0=(preds-y_train).mean()\n",
    "    g1=((preds-y_train)*x_train[:,0]).mean()  #each value multiplied in array\n",
    "    g2=((preds-y_train)*x_train[:,1]).mean()\n",
    "    g3=((preds-y_train)*x_train[:,2]).mean()\n",
    "    return(g0,g1,g2,g3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update parameters\n",
    "def update(t0,t1,t2,t3):\n",
    "    (g0,g1,g2,g3)=get_gradients(t0,t1,t2,t3)\n",
    "    t0=t0-alpha*g0 #g0 is slope\n",
    "    t1=t1-alpha*g1\n",
    "    t2=t2-alpha*g2\n",
    "    t3=t3-alpha*g3\n",
    "    return (t0,t1,t2,t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model/optimise\n",
    "def fit(t0,t1,t2,t3):\n",
    "    cost_progress=[]\n",
    "    for i in range(iterations):\n",
    "        t0,t1,t2,t3=update(t0,t1,t2,t3)\n",
    "        cost=get_cost(t0,t1,t2,t3)\n",
    "        cost_progress.append(cost)\n",
    "    return (t0,t1,t2,t3,cost_progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t0,t1,t2,t3,cost_progress)=fit(t0,t1,t2,t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(t0,t1,t2,t3,x,y,z):\n",
    "    return t0+t1*x+t2*y+t3*z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11202.7682073 , 11288.42115471, 11353.36870351, 11176.46936953,\n",
       "       11262.48914654, 11193.18042027, 11262.48914654, 11288.42115471,\n",
       "       11267.34892649, 11184.8248949 , 11245.41126621, 11410.32755652,\n",
       "       11211.12373267, 11292.7823322 , 11219.47925804, 11227.83478341,\n",
       "       11288.42115471, 11319.08116996, 11227.83478341, 11284.42680683,\n",
       "       11211.12373267, 11276.07128146, 11193.18042027, 11284.05997723,\n",
       "       11176.46936953, 11271.71010398, 11297.14350968, 11206.76255519,\n",
       "       11184.8248949 , 11349.00752602, 11168.11384416, 11223.47360592,\n",
       "       11223.47360592, 11288.42115471, 11292.7823322 , 11462.55840246,\n",
       "       11280.43245894, 11293.64776426, 11176.46936953, 11206.76255519,\n",
       "       11254.13362117, 11254.99905324, 11310.358815  , 11176.46936953,\n",
       "       11292.7823322 , 11327.43669533, 11176.46936953, 11272.07693357,\n",
       "       11345.01317814, 11262.48914654, 11276.07128146, 11219.47925804,\n",
       "       11219.47925804, 11227.83478341, 11288.42115471, 11253.76679158,\n",
       "       11219.47925804, 11228.70021547, 11275.70445186, 11323.07551785,\n",
       "       11184.8248949 , 11292.7823322 , 11297.14350968, 11202.7682073 ,\n",
       "       11258.12796906, 11319.08116996, 11293.64776426, 11206.76255519,\n",
       "       11336.65765277, 11193.18042027, 11211.12373267, 11227.83478341,\n",
       "       11193.18042027, 11315.08682208, 11258.99340113, 11254.13362117,\n",
       "       11206.76255519, 11219.47925804, 11237.42257043, 11253.76679158,\n",
       "       11341.01883025, 11297.14350968, 11275.70445186, 11233.06139295,\n",
       "       11168.11384416, 11193.18042027, 11176.46936953, 11254.13362117,\n",
       "       11184.8248949 , 11227.83478341, 11184.8248949 , 11184.8248949 ,\n",
       "       11371.3120159 , 11323.07551785, 11288.78798431, 11227.83478341,\n",
       "       11262.48914654, 11314.71999248, 11318.71434037, 11262.48914654,\n",
       "       11292.7823322 , 11262.48914654, 11176.46936953, 11193.18042027,\n",
       "       11258.12796906, 11176.46936953, 11237.42257043, 11193.18042027,\n",
       "       11206.76255519, 11353.36870351, 11262.48914654, 11198.40702982,\n",
       "       11227.83478341, 11327.43669533, 11388.38989624, 11349.37435562,\n",
       "       11263.7214082 , 11223.47360592, 11227.83478341, 11297.64211215,\n",
       "       11176.46936953, 11223.47360592, 11168.11384416, 11176.46936953,\n",
       "       11293.64776426, 11227.83478341, 11302.00328963, 11193.18042027,\n",
       "       11227.83478341, 11227.83478341, 11245.7780958 , 11215.11808055,\n",
       "       11216.35034221, 11262.48914654, 11410.32755652, 11184.8248949 ,\n",
       "       11193.18042027, 11284.42680683, 11297.14350968, 11271.71010398,\n",
       "       11249.77244369, 11249.77244369, 11215.11808055, 11345.01317814,\n",
       "       11271.71010398, 11448.60943795, 11193.18042027, 11184.8248949 ,\n",
       "       11275.70445186, 11288.78798431, 11354.23413557, 11223.47360592,\n",
       "       11276.07128146, 11302.37011923, 11258.99340113, 11262.48914654,\n",
       "       11184.8248949 , 11298.00894174, 11288.42115471, 11384.02871875,\n",
       "       11184.8248949 , 11341.01883025, 11288.78798431, 11258.12796906,\n",
       "       11223.47360592, 11288.42115471, 11193.18042027, 11345.01317814,\n",
       "       11262.48914654, 11193.18042027, 11292.7823322 , 11258.12796906,\n",
       "       11215.11808055, 11284.05997723, 11193.18042027, 11215.11808055,\n",
       "       11294.01459386, 11292.7823322 , 11249.77244369, 11176.46936953,\n",
       "       11219.47925804, 11168.11384416, 11280.06562935, 11251.00470535,\n",
       "       11184.8248949 , 11193.18042027, 11250.63787576, 11383.66188916,\n",
       "       11211.12373267, 11318.71434037, 11193.18042027, 11263.35457861,\n",
       "       11302.37011923, 11275.70445186, 11405.59954945, 11267.34892649,\n",
       "       11310.358815  , 11176.46936953, 11181.69597908, 11253.76679158,\n",
       "       11288.78798431, 11193.18042027, 11327.43669533, 11298.00894174,\n",
       "       11184.8248949 , 11193.18042027, 11285.29223889, 11267.34892649,\n",
       "       11184.8248949 , 11288.42115471, 11223.47360592, 11314.71999248,\n",
       "       11292.7823322 , 11323.07551785, 11258.12796906, 11227.83478341,\n",
       "       11219.47925804, 11357.72988099, 11206.76255519, 11258.12796906,\n",
       "       11297.14350968, 11211.12373267, 11323.07551785, 11319.08116996,\n",
       "       11314.71999248, 11241.41691832, 11254.13362117, 11176.46936953,\n",
       "       11319.08116996, 11253.76679158, 11241.41691832, 11253.76679158,\n",
       "       11258.99340113, 11262.48914654, 11168.11384416, 11276.07128146,\n",
       "       11284.05997723, 11415.18733648, 11227.83478341, 11159.75831879,\n",
       "       11168.11384416, 11327.43669533, 11219.47925804, 11292.7823322 ,\n",
       "       11193.18042027, 11318.71434037, 11379.30071168, 11193.18042027,\n",
       "       11292.7823322 , 11245.41126621, 11223.47360592, 11284.42680683,\n",
       "       11253.76679158, 11275.70445186, 11245.7780958 , 11198.40702982,\n",
       "       11206.76255519, 11159.75831879, 11254.13362117, 11211.12373267,\n",
       "       11318.71434037, 11315.08682208, 11284.05997723, 11288.42115471,\n",
       "       11211.12373267, 11323.07551785, 11388.02306664, 11193.18042027])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(t0,t1,t2,t3,x_test[:,0],x_test[:,1],x_test[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost function\n",
    "def get_cost_t(t0,t1,t2,t3):\n",
    "    preds=pred(t0,t1,t2,t3,x_test[:,0],x_test[:,1],x_test[:,2])  #error\n",
    "    J=(preds-y_test)**2 #squaring\n",
    "    J=J.mean()\n",
    "    J=J/2 \n",
    "    #print(J)#gradient decsent looks good\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79487552.83021235"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cost_t(t0,t1,t2,t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
