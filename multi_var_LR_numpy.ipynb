{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"multiple-lr-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding x and y\n",
    "# y=np.array(df['loan'])\n",
    "# x1=np.array(df['age'])\n",
    "# x2=np.array(df['credit-rating'])\n",
    "# x3=np.array(df['children'])\n",
    "a=np.array(df)\n",
    "x1=a[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding x and y\n",
    "# y=np.array(df['loan'])\n",
    "# x1=np.array(df['age'])\n",
    "# x2=np.array(df['credit-rating'])\n",
    "# x3=np.array(df['children'])\n",
    "a=np.array(df)\n",
    "x1=a[:,0]\n",
    "x2=a[:,1]\n",
    "x3=a[:,2]\n",
    "x=np.column_stack((x1,x2,x3))\n",
    "y=a[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 3)"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test split\n",
    "x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform of x for multiplication\n",
    "# sc = StandardScaler()\n",
    "# x_train = sc.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h=t0+t1x1+t2x2+tnxn\n",
    "#J is same as single var\n",
    "#gradient is error X xj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "alpha=0.0001\n",
    "iterations=100\n",
    "t0=800\n",
    "t1=800\n",
    "t2=800\n",
    "t3=800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction function\n",
    "def h(t0,t1,t2,t3):\n",
    "    return t0+(t1*x_train[:,0])+(t2*x_train[:,1])+(t3*x_train[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost function\n",
    "def get_cost(t0,t1,t2,t3):\n",
    "    preds=h(t0,t1,t2,t3)  #error\n",
    "    J=(preds-y_train)**2 #squaring\n",
    "    J=J.mean()\n",
    "    J=J/2 #gradient decsent looks good\n",
    "    #print(J)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing preds\n",
    "# def custom_plot(t0,t1,t2,t3):\n",
    "#     preds=h(t0,t1,t2,t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating gradients\n",
    "def get_gradients(t0,t1,t2,t3):\n",
    "    preds=h(t0,t1,t2,t3)\n",
    "    g0=(preds-y_train).mean()\n",
    "    g1=((preds-y_train)*x_train[:,0]).mean()  #each value multiplied in array\n",
    "    g2=((preds-y_train)*x_train[:,1]).mean()\n",
    "    g3=((preds-y_train)*x_train[:,2]).mean()\n",
    "    return(g0,g1,g2,g3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update parameters\n",
    "def update(t0,t1,t2,t3):\n",
    "    (g0,g1,g2,g3)=get_gradients(t0,t1,t2,t3)\n",
    "    t0=t0-alpha*g0 #g0 is slope\n",
    "    t1=t1-alpha*g1\n",
    "    t2=t2-alpha*g2\n",
    "    t3=t3-alpha*g3\n",
    "    return (t0,t1,t2,t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model/optimise\n",
    "def fit(t0,t1,t2,t3):\n",
    "    cost_progress=[]\n",
    "    for i in range(iterations):\n",
    "        t0,t1,t2,t3=update(t0,t1,t2,t3)\n",
    "        cost=get_cost(t0,t1,t2,t3)\n",
    "        cost_progress.append(cost)\n",
    "    return (t0,t1,t2,t3,cost_progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t0,t1,t2,t3,cost_progress)=fit(t0,t1,t2,t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(t0,t1,t2,t3,x,y,z):\n",
    "    return t0+t1*x+t2*y+t3*z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14269.79962815, 16662.04322508,  9858.02443907, 16291.11518957,\n",
       "       13789.94286177, 12101.10259213, 14957.83516406,  8906.05747196,\n",
       "       11063.69079311, 19386.08529734,  9195.18887748, 11781.35100797,\n",
       "       11311.80371292, 12449.0943447 , 17874.76939255, 14266.33340695,\n",
       "       14922.6126093 , 15712.29431462, 18631.45988396, 13831.20072814,\n",
       "       14947.73703207, 15078.3890221 , 12764.12910941,  9863.42425973,\n",
       "       18071.57569975, 12485.77883707, 16915.32986909, 10477.42017918,\n",
       "       14785.25371514, 11774.52535126, 11123.63978483, 16852.41811037,\n",
       "       13321.09372763, 16700.63419032, 12171.75098074, 15174.10722378,\n",
       "       14128.64011164, 15161.77252701, 11208.74499165, 14059.90250513,\n",
       "       16140.72718875, 16218.46008366, 15545.50169721, 12406.69753318,\n",
       "        8951.4740939 , 16369.3154371 , 16654.77303311, 12427.77054427,\n",
       "       13384.59777629, 11569.38114926, 10206.79512804, 16694.29347966,\n",
       "       18357.34579426, 11806.27737559, 13048.19788565, 15502.37437424,\n",
       "       15091.14264654, 14500.48530507, 13008.29983694,  7229.99886807,\n",
       "       15281.15752308, 15040.30957131, 17304.67542324, 12500.53299407,\n",
       "       11453.5873117 , 16281.43598525, 13198.9440197 ,  9019.59902682,\n",
       "       11609.03363258,  9760.68234619, 16365.09066315, 15647.08184824,\n",
       "       13689.35298649, 14503.86512423, 16269.51590692, 17451.90447742,\n",
       "       16425.38825492,  9818.00763778, 14334.20136579, 13761.06907792,\n",
       "        9201.41083557, 16773.51204426, 15962.14652977, 13718.79289448,\n",
       "       16697.96018973, 12934.53382719, 12018.07387202, 10256.14253359,\n",
       "        9575.68877343, 13424.66918728, 14783.19238813, 15481.66943214,\n",
       "       13462.22855126,  8820.62404872, 13318.47956068, 11179.83323073,\n",
       "       17321.07294038, 11481.91631585, 13896.70814568, 13729.59253581,\n",
       "        9438.34128794, 14120.99231751, 17440.47644459, 13781.52941542,\n",
       "       12850.1980236 ,  9262.18196471, 14329.84455507, 12991.5062095 ,\n",
       "       10838.09953781, 11206.51552632, 15850.91896676, 10099.2342751 ,\n",
       "       10328.73349663, 14273.6282918 , 10450.10239264, 13871.25363099,\n",
       "       12813.51971597, 16725.87736567, 13086.96033765,  9587.33336954,\n",
       "       13293.7099227 , 12124.19372921, 16802.74061291, 15179.05819995,\n",
       "        9738.93774257, 11250.35576731,  9310.6615981 , 13499.68579529,\n",
       "       13347.69672064, 12022.9023446 , 12720.31168578, 17096.03264951,\n",
       "       10174.97708533, 15657.19848836, 10970.7530212 , 10447.48822569,\n",
       "       18175.58859521, 14213.46273679, 12171.82840781, 17821.14260335,\n",
       "       12979.92763177, 14824.52768158,  7591.72123664, 16774.0630087 ,\n",
       "       11598.57549186, 10811.1004345 , 11795.32100462, 13793.96623214,\n",
       "       15270.36498122, 14728.10797055, 10385.87214175, 13322.26689882,\n",
       "       13447.16615891,  8451.54787638, 12522.28900637, 14126.12994015,\n",
       "       11514.11718467, 15869.21585731, 16077.66057589, 15648.46017404,\n",
       "       17763.45730302,  7974.19793306, 16285.72677759, 14372.18675689,\n",
       "       14649.22472181, 10629.28862575, 14879.26872304, 15267.6733872 ,\n",
       "       13199.56100252, 13257.58967896, 18322.71740495, 19375.0101738 ,\n",
       "       10522.29014592, 11324.22912095,  9752.549606  , 13586.56264799,\n",
       "       15034.6438016 , 14548.14280103, 10934.9927862 , 12837.16891694,\n",
       "       10081.92578478,  7448.63242989,  8976.26842476, 15658.15697178,\n",
       "       11309.25743986, 14453.40869036, 17948.45087578, 15292.6111635 ,\n",
       "       18835.47467398, 13383.26599994,  9675.10360199, 12824.67936604,\n",
       "       13271.10895562, 13930.52149702, 16298.73306688, 15423.0536897 ,\n",
       "       15200.45942745, 10306.93615883, 10069.43623388, 15362.59414433,\n",
       "       11922.0369871 , 11091.21804349, 16226.48360444, 12223.88591551,\n",
       "        9899.59911316, 14283.88837737,  9863.42425973, 11354.02716217,\n",
       "       13290.37142904, 11236.21763233, 14587.83660986, 14937.87118129,\n",
       "        7626.33821726,  9924.800963  , 17997.73936239, 12785.08671636,\n",
       "        8441.90999757, 12073.50932337, 12727.81081052, 14896.99801653,\n",
       "       12085.29736494, 10199.77141618,  8392.26860167, 15204.01879363,\n",
       "       14713.80169724,  8784.13051205,  8439.83726188, 11668.73183496,\n",
       "       12646.7869322 ,  9305.27318612, 13563.18984395, 18717.49700581,\n",
       "        9371.37811754, 12774.41911181, 13578.11832403,  9697.49510524,\n",
       "        9433.89376596, 14153.75743496, 10310.51403314, 14800.71034228,\n",
       "       13116.17749761, 10961.33170567, 14848.46564896, 11710.31979325,\n",
       "       12244.41227139,  9611.42619106,  7594.38813778, 13360.0033761 ,\n",
       "       16748.9219533 , 13406.14244924, 13755.65074912, 15635.44247607,\n",
       "       17846.37437002, 16450.41674249, 11274.00496828, 16720.477545  ,\n",
       "       13536.96967705, 15243.61666724, 10446.53592701, 17739.69457342,\n",
       "       16202.55273651, 10571.18439775, 19624.57549805, 16800.69069458,\n",
       "        9495.65517086, 10393.87472069,  8864.15270594, 15906.97850038])"
      ]
     },
     "execution_count": 748,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(t0,t1,t2,t3,x_test[:,0],x_test[:,1],x_test[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost function\n",
    "def get_cost_t(t0,t1,t2,t3):\n",
    "    preds=pred(t0,t1,t2,t3,x_test[:,0],x_test[:,1],x_test[:,2])  #error\n",
    "    J=(preds-y_test)**2 #squaring\n",
    "    J=J.mean()\n",
    "    J=J/2 \n",
    "    #print(J)#gradient decsent looks good\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8392.52265711867"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(get_cost_t(t0,t1,t2,t3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
