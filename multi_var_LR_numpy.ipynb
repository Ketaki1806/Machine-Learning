{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"multiple-lr-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding x and y\n",
    "# y=np.array(df['loan'])\n",
    "# x1=np.array(df['age'])\n",
    "# x2=np.array(df['credit-rating'])\n",
    "# x3=np.array(df['children'])\n",
    "a=np.array(df)\n",
    "x1=a[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding x and y\n",
    "# y=np.array(df['loan'])\n",
    "# x1=np.array(df['age'])\n",
    "# x2=np.array(df['credit-rating'])\n",
    "# x3=np.array(df['children'])\n",
    "a=np.array(df)\n",
    "x1=a[:,0]\n",
    "x2=a[:,1]\n",
    "x3=a[:,2]\n",
    "x=np.column_stack((x1,x2,x3))\n",
    "y=a[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 3)"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test split\n",
    "x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform of x for multiplication\n",
    "# sc = StandardScaler()\n",
    "# x_train = sc.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h=t0+t1x1+t2x2+tnxn\n",
    "#J is same as single var\n",
    "#gradient is error X xj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "alpha=0.0001\n",
    "iterations=100\n",
    "t0=800\n",
    "t1=800\n",
    "t2=800\n",
    "t3=800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction function\n",
    "def h(t0,t1,t2,t3):\n",
    "    return t0+(t1*x_train[:,0])+(t2*x_train[:,1])+(t3*x_train[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost function\n",
    "def get_cost(t0,t1,t2,t3):\n",
    "    preds=h(t0,t1,t2,t3)  #error\n",
    "    J=(preds-y_train)**2 #squaring\n",
    "    J=J.mean()\n",
    "    J=J/2 #gradient decsent looks good\n",
    "    #print(J)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing preds\n",
    "# def custom_plot(t0,t1,t2,t3):\n",
    "#     preds=h(t0,t1,t2,t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating gradients\n",
    "def get_gradients(t0,t1,t2,t3):\n",
    "    preds=h(t0,t1,t2,t3)\n",
    "    g0=(preds-y_train).mean()\n",
    "    g1=((preds-y_train)*x_train[:,0]).mean()  #each value multiplied in array\n",
    "    g2=((preds-y_train)*x_train[:,1]).mean()\n",
    "    g3=((preds-y_train)*x_train[:,2]).mean()\n",
    "    return(g0,g1,g2,g3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update parameters\n",
    "def update(t0,t1,t2,t3):\n",
    "    (g0,g1,g2,g3)=get_gradients(t0,t1,t2,t3)\n",
    "    t0=t0-alpha*g0 #g0 is slope\n",
    "    t1=t1-alpha*g1\n",
    "    t2=t2-alpha*g2\n",
    "    t3=t3-alpha*g3\n",
    "    return (t0,t1,t2,t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model/optimise\n",
    "def fit(t0,t1,t2,t3):\n",
    "    cost_progress=[]\n",
    "    for i in range(iterations):\n",
    "        t0,t1,t2,t3=update(t0,t1,t2,t3)\n",
    "        cost=get_cost(t0,t1,t2,t3)\n",
    "        cost_progress.append(cost)\n",
    "    return (t0,t1,t2,t3,cost_progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t0,t1,t2,t3,cost_progress)=fit(t0,t1,t2,t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(t0,t1,t2,t3,x,y,z):\n",
    "    return t0+t1*x+t2*y+t3*z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14265.96253121, 16679.54449574,  9854.15631063, 16291.30828218,\n",
       "       13809.18061909, 12096.57946701, 14960.36044068,  8903.49111123,\n",
       "       11063.28623528, 19382.99782756,  9178.79367696, 11777.26512731,\n",
       "       11312.74185181, 12444.09535808, 17878.6394989 , 14241.47669855,\n",
       "       14936.64988275, 15726.71238305, 18632.61327465, 13847.46077614,\n",
       "       14955.89736664, 15092.21327902, 12740.88392456,  9860.27907011,\n",
       "       18055.17031101, 12453.64141915, 16912.47841059, 10473.43538054,\n",
       "       14797.28785165, 11765.33654467, 11115.56236529, 16845.49207696,\n",
       "       13312.71135657, 16714.43107569, 12176.40411074, 15187.07026798,\n",
       "       14139.38116632, 15160.58864857, 11201.06018452, 14050.95251612,\n",
       "       16146.74717874, 16201.44611431, 15536.71119326, 12387.59273237,\n",
       "        8950.30627382, 16375.7531668 , 16628.11089735, 12412.06720798,\n",
       "       13379.04985784, 11552.88198279, 10203.91071857, 16688.09266343,\n",
       "       18348.36184672, 11798.5057953 , 13035.80674929, 15521.46143466,\n",
       "       15104.94946351, 14489.25086202, 13003.9968101 ,  7228.26378892,\n",
       "       15254.91309293, 15022.49436281, 17316.91598931, 12515.6913731 ,\n",
       "       11452.64958967, 16273.09977321, 13201.68352448,  9020.52901769,\n",
       "       11611.53495946,  9755.48668262, 16367.88255596, 15633.04017879,\n",
       "       13702.88571301, 14495.54735069, 16266.81724423, 17443.42835326,\n",
       "       16441.02217111,  9813.46390753, 14343.42201325, 13767.20050813,\n",
       "        9196.24962531, 16787.20927277, 15949.13467058, 13714.24862636,\n",
       "       16681.97250658, 12920.54981886, 12009.79133727, 10241.9481455 ,\n",
       "        9571.47640223, 13423.95739958, 14783.03518887, 15468.36294555,\n",
       "       13454.38350813,  8815.98354555, 13318.86463809, 11184.38211354,\n",
       "       17333.29108365, 11470.42767964, 13884.10836959, 13726.49414533,\n",
       "        9427.23483777, 14116.11939482, 17451.80098667, 13773.46907741,\n",
       "       12836.83832987,  9259.85894418, 14336.88019183, 12991.60808398,\n",
       "       10834.3518508 , 11208.10663117, 15848.57138143, 10097.22727258,\n",
       "       10327.14298809, 14277.81951027, 10441.26402328, 13868.18285922,\n",
       "       12788.01602348, 16742.56102348, 13089.12265176,  9585.29604337,\n",
       "       13281.20439402, 12126.2119334 , 16810.77662355, 15187.63253708,\n",
       "        9742.53568741, 11226.25930135,  9306.08131564, 13505.44433139,\n",
       "       13347.31152222, 12012.13458239, 12712.97218768, 17089.28247485,\n",
       "       10171.40586264, 15661.68871149, 10946.30857534, 10447.4173048 ,\n",
       "       18176.85637775, 14203.35110571, 12170.86018268, 17828.51632249,\n",
       "       12977.12404814, 14815.77141786,  7588.76119724, 16772.13504844,\n",
       "       11591.08793362, 10803.73805338, 11802.67985241, 13779.3159821 ,\n",
       "       15271.73256597, 14713.13198397, 10382.23386376, 13316.29522519,\n",
       "       13459.5694183 ,  8448.87271222, 12523.76283496, 14119.56801316,\n",
       "       11509.15742066, 15861.22200265, 16090.84870122, 15663.6958553 ,\n",
       "       17754.55514579,  7972.17552133, 16280.30598934, 14389.16767889,\n",
       "       14645.09011308, 10628.01744576, 14899.2078496 , 15283.42977554,\n",
       "       13185.94490545, 13246.37285531, 18318.67173645, 19378.28942075,\n",
       "       10501.38024209, 11323.46828985,  9746.63474075, 13554.60194155,\n",
       "       15024.36090211, 14524.14004462, 10927.46098842, 12831.63925755,\n",
       "       10079.94245077,  7446.59838017,  8972.87573122, 15637.74858559,\n",
       "       11312.89901866, 14458.59338042, 17938.56542618, 15299.79091019,\n",
       "       18827.29755448, 13397.21728526,  9679.51915966, 12816.24549424,\n",
       "       13271.55880999, 13931.530283  , 16295.26412836, 15442.97954003,\n",
       "       15214.11675913, 10304.64513426, 10064.54868747, 15351.86278898,\n",
       "       11913.37678847, 11088.58487507, 16201.8677789 , 12221.3858587 ,\n",
       "        9899.32574747, 14300.25972022,  9860.27907011, 11356.14687496,\n",
       "       13289.33429732, 11222.14368567, 14597.21941324, 14934.80250843,\n",
       "        7623.33084085,  9913.0293033 , 18006.33223982, 12796.2043682 ,\n",
       "        8445.09059522, 12071.94522192, 12708.04556996, 14897.41551651,\n",
       "       12079.5565403 , 10193.97532005,  8390.4048218 , 15194.23460503,\n",
       "       14730.31547771,  8775.37930836,  8435.71746579, 11656.25741496,\n",
       "       12636.62668432,  9295.0790228 , 13571.78283265, 18714.59347462,\n",
       "        9365.47549586, 12782.63005982, 13573.25743185,  9696.03746116,\n",
       "        9436.44819772, 14129.5636582 , 10308.94843882, 14793.44729322,\n",
       "       13117.56953589, 10964.71873288, 14841.64628644, 11691.21559849,\n",
       "       12226.99003327,  9600.08305585,  7592.15477433, 13349.15549635,\n",
       "       16723.37038593, 13399.32575713, 13736.89228998, 15653.61724963,\n",
       "       17861.52580363, 16441.62812438, 11269.88253541, 16736.438264  ,\n",
       "       13543.4075521 , 15248.67244305, 10432.08118538, 17736.44615979,\n",
       "       16205.05790232, 10567.80170399, 19613.1283538 , 16791.64442742,\n",
       "        9490.09159603, 10387.08287508,  8861.64364791, 15924.05163906])"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(t0,t1,t2,t3,x_test[:,0],x_test[:,1],x_test[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost function\n",
    "def get_cost_t(t0,t1,t2,t3):\n",
    "    preds=pred(t0,t1,t2,t3,x_test[:,0],x_test[:,1],x_test[:,2])  #error\n",
    "    J=(preds-y_test)**2 #squaring\n",
    "    J=J.mean()\n",
    "    J=J/2 \n",
    "    #print(J)#gradient decsent looks good\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70434372.00743824"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cost_t(t0,t1,t2,t3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
