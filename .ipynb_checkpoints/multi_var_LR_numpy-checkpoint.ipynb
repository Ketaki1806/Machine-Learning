{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"multiple-lr-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding x and y\n",
    "# y=np.array(df['loan'])\n",
    "# x1=np.array(df['age'])\n",
    "# x2=np.array(df['credit-rating'])\n",
    "# x3=np.array(df['children'])\n",
    "a=np.array(df)\n",
    "x1=a[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding x and y\n",
    "# y=np.array(df['loan'])\n",
    "# x1=np.array(df['age'])\n",
    "# x2=np.array(df['credit-rating'])\n",
    "# x3=np.array(df['children'])\n",
    "a=np.array(df)\n",
    "x1=a[:,0]\n",
    "x2=a[:,1]\n",
    "x3=a[:,2]\n",
    "x=np.column_stack((x1,x2,x3))\n",
    "y=a[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 3)"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test split\n",
    "x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform of x for multiplication\n",
    "# sc = StandardScaler()\n",
    "# x_train = sc.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h=t0+t1x1+t2x2+tnxn\n",
    "#J is same as single var\n",
    "#gradient is error X xj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "alpha=0.0001\n",
    "iterations=100\n",
    "t0=795\n",
    "t1=795\n",
    "t2=795\n",
    "t3=795"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction function\n",
    "def h(t0,t1,t2,t3):\n",
    "    return t0+(t1*x_train[:,0])+(t2*x_train[:,1])+(t3*x_train[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost function\n",
    "def get_cost(t0,t1,t2,t3):\n",
    "    preds=h(t0,t1,t2,t3)  #error\n",
    "    J=(preds-y_train)**2 #squaring\n",
    "    J=J.mean()\n",
    "    J=J/2 #gradient decsent looks good\n",
    "    #print(J)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing preds\n",
    "# def custom_plot(t0,t1,t2,t3):\n",
    "#     preds=h(t0,t1,t2,t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating gradients\n",
    "def get_gradients(t0,t1,t2,t3):\n",
    "    preds=h(t0,t1,t2,t3)\n",
    "    g0=(preds-y_train).mean()\n",
    "    g1=((preds-y_train)*x_train[:,0]).mean()  #each value multiplied in array\n",
    "    g2=((preds-y_train)*x_train[:,1]).mean()\n",
    "    g3=((preds-y_train)*x_train[:,2]).mean()\n",
    "    return(g0,g1,g2,g3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update parameters\n",
    "def update(t0,t1,t2,t3):\n",
    "    (g0,g1,g2,g3)=get_gradients(t0,t1,t2,t3)\n",
    "    t0=t0-alpha*g0 #g0 is slope\n",
    "    t1=t1-alpha*g1\n",
    "    t2=t2-alpha*g2\n",
    "    t3=t3-alpha*g3\n",
    "    return (t0,t1,t2,t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model/optimise\n",
    "def fit(t0,t1,t2,t3):\n",
    "    cost_progress=[]\n",
    "    for i in range(iterations):\n",
    "        t0,t1,t2,t3=update(t0,t1,t2,t3)\n",
    "        cost=get_cost(t0,t1,t2,t3)\n",
    "        cost_progress.append(cost)\n",
    "    return (t0,t1,t2,t3,cost_progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t0,t1,t2,t3,cost_progress)=fit(t0,t1,t2,t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(t0,t1,t2,t3,x,y,z):\n",
    "    return t0+t1*x+t2*y+t3*z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14261.57727757, 16699.54594792,  9849.73559242, 16291.52895944,\n",
       "       13831.16662747, 12091.41018115, 14963.24647111,  8900.55812755,\n",
       "       11062.82388347, 19379.46929065,  9160.05630493, 11772.59554941,\n",
       "       11313.81401055, 12438.38223051, 17883.06247758, 14213.06903181,\n",
       "       14952.69248098, 15743.19017553, 18633.93143543, 13866.04368813,\n",
       "       14965.22346328, 15108.01242978, 12714.31799902,  9856.6845677 ,\n",
       "       18036.42129529, 12416.91294152, 16909.21960087, 10468.88132494,\n",
       "       14811.04115051, 11754.83505144, 11106.33102867, 16837.5766102 ,\n",
       "       13303.13150394, 16730.19894468, 12181.72197359, 15201.88517564,\n",
       "       14151.65665739, 15159.23564465, 11192.2775478 , 14040.72395726,\n",
       "       16153.62716731, 16182.00157792, 15526.66490304, 12365.75867431,\n",
       "        8948.97162229, 16383.11057216, 16597.63988506, 12394.12053792,\n",
       "       13372.7093796 , 11534.02579254, 10200.6142506 , 16681.0060163 ,\n",
       "       18338.09447811, 11789.62398927, 13021.64545059, 15543.27521799,\n",
       "       15120.7286829 , 14476.41149854, 12999.07906514,  7226.28084131,\n",
       "       15224.91945848, 15002.13412453, 17330.90520767, 12533.01523484,\n",
       "       11451.57790736, 16263.57267373, 13204.81438709,  9021.59186441,\n",
       "       11614.39361875,  9749.54878141, 16371.0732906 , 15616.99255656,\n",
       "       13718.35168618, 14486.04132379, 16263.73305831, 17433.74135422,\n",
       "       16458.88950389,  9808.27107296, 14353.95989607, 13774.20785694,\n",
       "        9190.35109929, 16802.86324821, 15934.26397436, 13709.05517708,\n",
       "       16663.70086871, 12904.56809505, 12000.32558326, 10225.72598768,\n",
       "        9566.66226372, 13423.14392793, 14782.85553257, 15453.1555323 ,\n",
       "       13445.41774455,  8810.68011335, 13319.30472657, 11189.58083675,\n",
       "       17347.25467596, 11457.29780969, 13869.70862548, 13722.95312765,\n",
       "        9414.54175186, 14110.55034033, 17464.74332048, 13764.25726253,\n",
       "       12821.57010847,  9257.20406357, 14344.92091955, 12991.72451196,\n",
       "       10830.06877994, 11209.9250367 , 15845.88842677, 10094.93355541,\n",
       "       10325.32526405, 14282.60947424, 10431.16302973, 13864.67340577,\n",
       "       12758.86894635, 16761.62806099, 13091.5938679 ,  9582.9676706 ,\n",
       "       13266.91236125, 12128.51845246, 16819.96063572, 15197.43177951,\n",
       "        9746.64762436, 11198.7204831 ,  9300.84670711, 13512.0255155 ,\n",
       "       13346.87129546, 11999.82856844, 12704.58418985, 17081.56798951,\n",
       "       10167.32446529, 15666.82039508, 10918.37206579, 10447.33625236,\n",
       "       18178.30527209, 14191.79495591, 12169.75363969, 17836.94343007,\n",
       "       12973.91995256, 14805.76425933,  7585.37829507, 16769.93166529,\n",
       "       11582.5307242 , 10795.32390352, 11811.08996417, 13762.57283919,\n",
       "       15273.29551998, 14696.01657073, 10378.07583177, 13309.47045532,\n",
       "       13473.7445719 ,  8445.81538176, 12525.4472105 , 14112.06866802,\n",
       "       11503.48911894, 15852.08616875, 16105.92084446, 15681.10806246,\n",
       "       17744.38125182,  7969.86419364, 16274.11080277, 14408.57444688,\n",
       "       14640.36484596, 10626.56466863, 14921.9954228 , 15301.43707651,\n",
       "       13170.38365166, 13233.55362828, 18314.04811532, 19382.03713155,\n",
       "       10477.48320914, 11322.59876859,  9739.87489474, 13518.0754199 ,\n",
       "       15012.60901698, 14496.708323  , 10918.85321952, 12825.31964681,\n",
       "       10077.67578333,  7444.27375191,  8968.99836718, 15614.42471567,\n",
       "       11317.06082299, 14464.51874048, 17927.26776951, 15307.99633498,\n",
       "       18817.95227506, 13413.16161135,  9684.56551129, 12806.60678362,\n",
       "       13272.07292927, 13932.68318126, 16291.2996272 , 15465.75194042,\n",
       "       15229.72513819, 10302.02682048, 10058.96292014, 15339.59838286,\n",
       "       11903.4794186 , 11085.57553974, 16173.73540685, 12218.52865092,\n",
       "        9899.01332954, 14318.96982633,  9856.6845677 , 11358.56940387,\n",
       "       13288.14900391, 11206.0591752 , 14607.94261712, 14931.29545374,\n",
       "        7619.89383924,  9899.57597793, 18016.15267117, 12808.91025601,\n",
       "        8448.72556396, 12070.1576774 , 12685.4567236 , 14897.89265935,\n",
       "       12072.99559786, 10187.35121018,  8388.27478766, 15183.0526752 ,\n",
       "       14749.18836968,  8765.37793271,  8431.0091274 , 11642.00093497,\n",
       "       12625.01497245,  9283.42855044, 13581.60339117, 18711.27515324,\n",
       "        9358.72964252, 12792.01400041, 13567.70212651,  9694.3715822 ,\n",
       "        9439.36754829, 14101.91362762, 10307.15918817, 14785.14666572,\n",
       "       13119.16043679, 10968.58962112, 14833.85272929, 11669.38223304,\n",
       "       12207.07890399,  9587.11947275,  7589.60235897, 13336.7579195 ,\n",
       "       16694.16859465, 13391.53525187, 13715.45405097, 15674.38841941,\n",
       "       17878.84172777, 16431.5839894 , 11265.17118357, 16754.6790857 ,\n",
       "       13550.76512358, 15254.45047254, 10415.56148065, 17732.73368707,\n",
       "       16207.92094896, 10563.93576826, 19600.04590322, 16781.30583638,\n",
       "        9483.7332248 , 10379.32076581,  8858.77615302, 15943.56379754])"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(t0,t1,t2,t3,x_test[:,0],x_test[:,1],x_test[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost function\n",
    "def get_cost_t(t0,t1,t2,t3):\n",
    "    preds=pred(t0,t1,t2,t3,x_test[:,0],x_test[:,1],x_test[:,2])  #error\n",
    "    J=(preds-y_test)**2 #squaring\n",
    "    J=J.mean()\n",
    "    J=J/2 \n",
    "    #print(J)#gradient decsent looks good\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70434439.8753968"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cost_t(t0,t1,t2,t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "#790:70434379.75402616\n",
    "#785:70434439.8753968\n",
    "#780:70434559.00975583"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
